{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the coordinates of the Sunnyvale city open street map data I will be working on. I have downloadede the data from the Overpass API link provided in the project details. \n",
    "Minimum Latitude : 37.3499 Maximum Latitude: 37.3863 Minimum Longitude: -122.0654 Maximum Longitude: -121.9782\n",
    "\n",
    "Below is the code to understand different tags in the data and counts against each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 7369,\n",
      " 'meta': 1,\n",
      " 'nd': 293169,\n",
      " 'node': 250586,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 499,\n",
      " 'tag': 96905,\n",
      " 'way': 35156}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    # YOUR CODE HERE\n",
    "    tags = {}\n",
    "    osm_file = open(filename, 'r')\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        #print elem.tag\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag] = tags[elem.tag]+1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "    return tags\n",
    "\n",
    "data = 'C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/interpreter'\n",
    "tags = count_tags(data)\n",
    "pprint.pprint(tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code I can see that there are Nodes and Ways. I will be working on getting these into a database and analyzing further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 63283, 'lower_colon': 32580, 'other': 1042, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        \n",
    "        if lower.match(element.attrib['k']):\n",
    "            keys['lower'] = keys['lower']+1\n",
    "        elif lower_colon.match(element.attrib['k']):\n",
    "            keys['lower_colon'] = keys['lower_colon'] + 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] =keys['problemchars'] + 1\n",
    "        else:\n",
    "            keys['other'] = keys['other'] +1\n",
    "        #print element.attrib['k']\n",
    "        #print keys\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "keys = process_map(data)\n",
    "pprint.pprint(keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used the code I worked on in the exercise. Looks like there are lower colons in 32580 tags. I want to continue the way we have split the keys into type and the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['25or6to4',\n",
      "     '42429',\n",
      "     'ACE|Tony',\n",
      "     'AKOK',\n",
      "     'Aaron Lidman',\n",
      "     'Ahlzen',\n",
      "     'Aidan703',\n",
      "     'Alan Pierrat',\n",
      "     'Alan Vogt',\n",
      "     'Aleks-Berlin',\n",
      "     'Alexander Avtanski',\n",
      "     'AndiG88',\n",
      "     'Andrew Hazlett',\n",
      "     'AndrewSnow',\n",
      "     'Ankur Datta',\n",
      "     'Apo42',\n",
      "     'Ashish Vijayaram',\n",
      "     'Ashvini Kumar',\n",
      "     'Aury88',\n",
      "     'AvinashR',\n",
      "     'Azlux',\n",
      "     'BCNorwich',\n",
      "     'Ben Luo',\n",
      "     'Bhaskar U',\n",
      "     'Bhojaraj',\n",
      "     'Bike Mapper',\n",
      "     'Blue Skyes Acupuncture',\n",
      "     'Bman',\n",
      "     'BobbyAndThomas',\n",
      "     'Brian2433',\n",
      "     'Brian@Brea',\n",
      "     'Bryce C Nesbitt',\n",
      "     'BugBuster',\n",
      "     'BuganiniQ',\n",
      "     'Cato_d_Ae',\n",
      "     'Chaitanya Kumar CH',\n",
      "     'Chetan91',\n",
      "     'Chetan_Gowda',\n",
      "     'ChrisZontine',\n",
      "     'CitymapperHQ',\n",
      "     'CloCkWeRX',\n",
      "     'CongoMan',\n",
      "     'CoreyFarwell',\n",
      "     'DanHomerick',\n",
      "     'Dana_Bringas',\n",
      "     'Daniel_Caldwell',\n",
      "     'David Muir Sharnoff',\n",
      "     'David Speakman',\n",
      "     'Dero Bike Racks',\n",
      "     'Dhruv Matani',\n",
      "     'Dr Kludge',\n",
      "     'Dvorty',\n",
      "     'Eric Fischer',\n",
      "     'Field Enterprise',\n",
      "     'FvGordon',\n",
      "     'Gan Louy',\n",
      "     'Geogast',\n",
      "     'GoWestTravel',\n",
      "     'Hardaker',\n",
      "     'HardeepRai',\n",
      "     'Harry Cutts',\n",
      "     'Head',\n",
      "     'Hedaja',\n",
      "     'Hjart',\n",
      "     'Iowa Kid',\n",
      "     'Iwantsummer',\n",
      "     'JDub',\n",
      "     'Jack J Jia',\n",
      "     'Jake Strine',\n",
      "     'JasonBuberel',\n",
      "     'JayXon',\n",
      "     'Jedrzej Pelka',\n",
      "     'JeffM8',\n",
      "     'JoanL',\n",
      "     'Joel Franusic',\n",
      "     'John Licking',\n",
      "     'Jonah',\n",
      "     'Jonathan ZHAO',\n",
      "     'Jothirnadh',\n",
      "     'KR-KRKR-KR',\n",
      "     'Katei',\n",
      "     'KayLinMa',\n",
      "     'KevinB',\n",
      "     'KindredCoda',\n",
      "     'KiwiJ',\n",
      "     'KristenK',\n",
      "     'L0g1x',\n",
      "     'LXT',\n",
      "     'Lee Barford',\n",
      "     'Legoktm',\n",
      "     'Looterius',\n",
      "     'Luis36995',\n",
      "     'MannequinBaby',\n",
      "     'Manu1400',\n",
      "     'Marcus Wolschon',\n",
      "     'Marion Barry',\n",
      "     'Math1985',\n",
      "     'MatthieuMartin',\n",
      "     'Max Planck',\n",
      "     'Md Alamgir',\n",
      "     'Michael Ficarra',\n",
      "     'MikeN',\n",
      "     'Mikhail Kravchenko',\n",
      "     'Minh Nguyen',\n",
      "     'MintCondition',\n",
      "     'MoonshineFiesta',\n",
      "     'Mouskegamer',\n",
      "     'NicktheDoggo',\n",
      "     'NiveM',\n",
      "     'OMapper',\n",
      "     'OSMF Redaction Account',\n",
      "     'OSMerThanThou',\n",
      "     'Omnific',\n",
      "     'PemFR',\n",
      "     'Perch338',\n",
      "     'Peter Black',\n",
      "     'Peter Dobratz',\n",
      "     'Phil Scherer',\n",
      "     'PhilRW',\n",
      "     'PlaneMad',\n",
      "     'Prasanth Rajan',\n",
      "     'Prashanth Gedde',\n",
      "     'R0bst3r',\n",
      "     'RMap1',\n",
      "     'Randomandy',\n",
      "     'RaymondRanger',\n",
      "     'RichRico',\n",
      "     'RichardNixxon',\n",
      "     'Rockear',\n",
      "     'Rub21',\n",
      "     'Ryan Holliday',\n",
      "     'Shawn Britton',\n",
      "     'Skybunny',\n",
      "     'SomeoneElse_Revert',\n",
      "     'SophoM',\n",
      "     'Stealthguy05',\n",
      "     'StellanL',\n",
      "     'Stemby',\n",
      "     'Stephen214',\n",
      "     'SteveC',\n",
      "     'Steven Bell',\n",
      "     'Tad-osm',\n",
      "     'Telecas',\n",
      "     'TheDutchMan13',\n",
      "     'Tim Oey',\n",
      "     'Tom_Holland',\n",
      "     'TorieRob',\n",
      "     'Tuyen Duong',\n",
      "     'VMukhtarov',\n",
      "     'Vance Callinan',\n",
      "     'WZ Bzrandt',\n",
      "     'Walk and walk around',\n",
      "     u'Walter Schl\\xf6gl',\n",
      "     'Wenya',\n",
      "     'WrErase',\n",
      "     'YagilH',\n",
      "     'YongYang',\n",
      "     'YraFyra',\n",
      "     'Yunjie',\n",
      "     'Zian Choy',\n",
      "     '\\\\Mike',\n",
      "     '_sev',\n",
      "     'a6y',\n",
      "     'aarohip',\n",
      "     'abel801',\n",
      "     'acwan93',\n",
      "     'adbrown',\n",
      "     'afdreher',\n",
      "     'ahabot',\n",
      "     'aksalive',\n",
      "     'amillar',\n",
      "     'andrewpmk',\n",
      "     'andygol',\n",
      "     'arenevier',\n",
      "     'ashleyannmathew',\n",
      "     'baditaflorin',\n",
      "     'balrog-kun',\n",
      "     'bbmiller',\n",
      "     'bdeo',\n",
      "     'beddy',\n",
      "     'beweta',\n",
      "     'bibi6',\n",
      "     'bill42',\n",
      "     'bmhr',\n",
      "     'bob098',\n",
      "     'boeleman81',\n",
      "     'bruhaha876',\n",
      "     'c4555603',\n",
      "     'c4557621',\n",
      "     'calfarome',\n",
      "     'caminti',\n",
      "     'cdavila',\n",
      "     'cfrost',\n",
      "     'chliju',\n",
      "     'chukka',\n",
      "     'claysmalley',\n",
      "     'colindt',\n",
      "     'dannykath',\n",
      "     'danrushing',\n",
      "     'davidearl',\n",
      "     'dbaupp',\n",
      "     'djsnaxz',\n",
      "     'dkim74542',\n",
      "     'doj',\n",
      "     'dommage',\n",
      "     'dpaschich',\n",
      "     'drfuentes',\n",
      "     'droctagonopus',\n",
      "     'drrd13',\n",
      "     'dufflebunk',\n",
      "     'ediyes',\n",
      "     'egore911',\n",
      "     'elbatrop',\n",
      "     'encleadus',\n",
      "     'eric22',\n",
      "     'erjiang',\n",
      "     'esuor',\n",
      "     'exaclyme',\n",
      "     'f2003104',\n",
      "     'falsifian',\n",
      "     'fennecfoxen',\n",
      "     'flierfy',\n",
      "     'flofanse',\n",
      "     'fmarier',\n",
      "     'frizzby',\n",
      "     'gabis_telenav',\n",
      "     'gaku',\n",
      "     'geodreieck4711',\n",
      "     'gfxblit',\n",
      "     'haixia shen',\n",
      "     'hfyu',\n",
      "     'iandees',\n",
      "     'j03lar50n',\n",
      "     'jgkamat',\n",
      "     'joeclmbr',\n",
      "     'jonesydesign',\n",
      "     'jotdown',\n",
      "     'jpx_',\n",
      "     'jumbanho',\n",
      "     'karitotp',\n",
      "     'kisaa',\n",
      "     'kjon',\n",
      "     'logatron',\n",
      "     'lxbarth',\n",
      "     'maggot27',\n",
      "     'manings',\n",
      "     'manoharuss',\n",
      "     'manoj_telenav',\n",
      "     'marinad_telenav',\n",
      "     'mark7',\n",
      "     'marthaleena',\n",
      "     'matthieun',\n",
      "     'maxerickson',\n",
      "     'mchowla',\n",
      "     'mcpherrinm',\n",
      "     'mihaii_telenav',\n",
      "     'mk408',\n",
      "     'mmaapp',\n",
      "     'mprojekt',\n",
      "     'muziriana',\n",
      "     'mvexel',\n",
      "     'mxyzptlk',\n",
      "     'myxor',\n",
      "     'n76',\n",
      "     'nammala',\n",
      "     'nereocystis',\n",
      "     'neuhausr',\n",
      "     'niceguy_reddy',\n",
      "     'nikhilprabhakar',\n",
      "     'nithinkamath',\n",
      "     'njaard',\n",
      "     'nmixter',\n",
      "     'nyuriks',\n",
      "     'oba510',\n",
      "     'oldtopos',\n",
      "     'oloprnmq',\n",
      "     'oormilavinod',\n",
      "     'p3lee',\n",
      "     'pallindo',\n",
      "     'patelbhavesh',\n",
      "     'pawloch',\n",
      "     'pbfoot06',\n",
      "     'perdoliki',\n",
      "     'phoenix23',\n",
      "     'piligab',\n",
      "     'pitosakiph',\n",
      "     'pluton_od',\n",
      "     'pratikyadav',\n",
      "     'quackers',\n",
      "     'raf',\n",
      "     'ramyaragupathy',\n",
      "     'rayKiddy',\n",
      "     'rhildebrand',\n",
      "     'richlv',\n",
      "     'ridixcr',\n",
      "     'rolandg',\n",
      "     'rowers2',\n",
      "     'runningman',\n",
      "     'ruthmaben',\n",
      "     'ryandrake',\n",
      "     'ryebread',\n",
      "     'rza31',\n",
      "     'sabata2',\n",
      "     'saikabhi',\n",
      "     'samely',\n",
      "     'seattlefyi',\n",
      "     'sebastic',\n",
      "     'skobbler',\n",
      "     'srividya_c',\n",
      "     'sstangl',\n",
      "     'stevea',\n",
      "     'steverumizen',\n",
      "     'stoth',\n",
      "     'surveyor54',\n",
      "     'tahongawaka',\n",
      "     'tamakio',\n",
      "     'teodorab_telenav',\n",
      "     'titanduan',\n",
      "     'uboot',\n",
      "     'upendrakarukonda',\n",
      "     'user_5359',\n",
      "     'vchernetsky',\n",
      "     'vicb',\n",
      "     'wallclimber21',\n",
      "     'warutledge',\n",
      "     'werner2101',\n",
      "     'wheelmap_visitor',\n",
      "     'whereissean',\n",
      "     'woodpeck_fixbot',\n",
      "     'woodpeck_repair',\n",
      "     'xybot',\n",
      "     'yiqingj',\n",
      "     'yurasi'])\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.tag in ['node', 'way', 'relation']:\n",
    "            #print element.tag\n",
    "            users.add(element.attrib['user'])\n",
    "    return users\n",
    "\n",
    "users = process_map(data)\n",
    "pprint.pprint(users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code I have got the list of all the users who have contributed in creating this data from nodes, ways and relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': set(['Stewart Drive Suite #1']),\n",
      " '114': set(['West Evelyn Avenue Suite #114']),\n",
      " 'Ave': set(['W Washington Ave']),\n",
      " 'Circle': set(['Bobolink Circle', 'Continental Circle']),\n",
      " 'East': set(['Vanderbilt Court East']),\n",
      " 'Oaks': set(['North Fair Oaks']),\n",
      " 'Rd': set(['Wolfe Rd']),\n",
      " 'West': set(['Vanderbilt Court West'])}\n",
      "------------------------------------\n",
      "Wolfe Rd => Wolfe Road\n",
      "W Washington Ave => W Washington Avenue\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = data\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Terrace\", \"Way\", \"Expressway\", \"Real\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Ln\": \"Lane\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"PKWY\": \"Parkway\",\n",
    "            \"Blvd\": \"Boulevard\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = name[:-len(street_type)] + mapping[street_type]\n",
    "            #name = name.replace(street_type, mapping[street_type])\n",
    "    return name\n",
    "\n",
    "\n",
    "st_types = audit(OSMFILE)\n",
    "pprint.pprint(dict(st_types))\n",
    "print \"------------------------------------\"\n",
    "\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        if name != better_name:\n",
    "            print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408) 738-CHEF\n",
      "+1 408 7339000\n",
      "+1 408 746-0646\n",
      "+1-650-938-NYNY\n",
      "+16502898186\n",
      "+1 408-962-0396\n",
      "+1 408-730-9200\n",
      "+1 408-260-2727\n",
      "+1 408-247-4300\n",
      "(408)-732-0300\n",
      "+1 408 2691048\n",
      "+1 (408) 245-8434\n"
     ]
    }
   ],
   "source": [
    "# Phone numbers analysis\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "data = 'C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/interpreter'\n",
    "OSMFILE = data\n",
    "\n",
    "#below function would audit all types of phone numbers. I worked on the regex to build it incrementally adding all the different formats of phone numbers\n",
    "def auditphone(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    phone_type = re.compile(r'^1\\.[0-9]{3}\\.[0-9]{3}\\.[0-9]{4}$|^\\+1\\-[0-9]{3}\\-[0-9]{3}\\-[0-9]{4}$|^[0-9]{3}\\.[0-9]{3}\\.[0-9]{4}$|^[0-9]{3}\\.[0-9]{3}\\.[A-Z]{4}$|^[0-9]{10}$|^\\+1\\s[0-9]{3}\\s[0-9]{3}\\s[0-9]{4}$|^1\\s[0-9]{3}\\s[0-9]{3}\\s[0-9]{4}$|^[0-9]{3}\\s[0-9]{3}\\s[0-9]{4}$|^[0-9]{3}\\-[0-9]{3}\\-[0-9]{4}$|^\\([0-9]{3}\\)\\s[0-9]{3}\\-[0-9]{4}$|^\\+1\\.[0-9]{3}\\.[0-9]{3}\\.[0-9]{4}$', re.IGNORECASE)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k']=='phone':\n",
    "                    m = phone_type.search(tag.attrib['v'])\n",
    "                    if not m:\n",
    "                        print tag.attrib['v']\n",
    "    osm_file.close()\n",
    "     \n",
    "auditphone(OSMFILE)\n",
    "\n",
    "#Below function is used to conver the alphabets in the phone numbers to the numbers based on the T9 formating. I refered to a stackoverflow code for this.\n",
    "def alpha_num(input):\n",
    "  \n",
    "    key_alph='abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    key_num= '22233344455566677778889999'\n",
    "    \n",
    "    counter = len(input)\n",
    "    #print counter\n",
    "    total=''    #Stores the part of string which is not going to be changed\n",
    "    #print total\n",
    "    while (counter>0):\n",
    "        alpha = input.lower()[-counter]\n",
    "        #print counter\n",
    "        #print alpha\n",
    "        if alpha.isalpha():   #checks if each character in the input is a valid alphabet and not a number.\n",
    "            total+=key_num[key_alph.index(alpha)]  #Appending the new characters  \n",
    "        else:\n",
    "            total+=alpha     #This will preserve if any numeric character is encountered and keeps it same as in the input\n",
    "        counter -= 1\n",
    "    return total\n",
    "\n",
    "# below function corrects all different formats of numbers into standart format +1XXXXXXXXXX\n",
    "def format_phone(test):\n",
    "\n",
    "    if re.match('^[0-9]{10}$', test):\n",
    "        number = '+1'+test\n",
    "    elif re.match('^1[0-9]{10}$',test):\n",
    "        number = '+'+test\n",
    "    elif re.match('^\\+1[0-9]{10}$',test):\n",
    "        number = test\n",
    "    elif re.match('^\\([0-9]{3}\\)\\s[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = '+1'+test[1:4]+test[6:9]+test[10:]\n",
    "    elif re.match('^\\([0-9]{3}\\)\\-[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = '+1'+test[1:4]+test[6:9]+test[10:]\n",
    "    elif re.match('^\\+1\\s\\([0-9]{3}\\)\\s[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = '+1'+test[4:7]+test[9:12]+test[13:]\n",
    "    elif re.match('^[0-9]{3}\\s[0-9]{3}\\s[0-9]{4}$',test):\n",
    "        number = '+1'+test.replace(' ','')\n",
    "    elif re.match('^\\+1\\s[0-9]{3}\\s[0-9]{3}\\s[0-9]{4}$',test):\n",
    "        number = test.replace(' ','')\n",
    "    elif re.match('^\\+1\\s[0-9]{3}\\s[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = test.replace(' ','').replace('-','')\n",
    "    elif re.match('^\\+1\\-[0-9]{3}\\-[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = test.replace('-','')\n",
    "    elif re.match('^\\+1\\s[0-9]{3}\\s[0-9]{7}$',test):\n",
    "        number = test.replace(' ','')\n",
    "    elif re.match('^\\+1\\s[0-9]{3}\\-[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = test.replace(' ','').replace('-','')\n",
    "    elif re.match('^\\+1\\.[0-9]{3}\\.[0-9]{3}\\.[0-9]{4}$',test):\n",
    "        number = test.replace('.','')\n",
    "    elif re.match('^1\\.[0-9]{3}\\.[0-9]{3}\\.[0-9]{4}$',test):\n",
    "        number = '+'+test.replace('.','')\n",
    "    elif re.match('^1\\s[0-9]{3}\\s[0-9]{3}\\s[0-9]{4}$',test):\n",
    "        number = '+'+test.replace(' ','')\n",
    "    elif re.match('^[0-9]{3}\\.[0-9]{3}\\.[0-9]{4}$',test):\n",
    "        number = '+1'+test.replace('.','')\n",
    "    elif re.match('^[0-9]{3}\\-[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = '+1'+test.replace('-','')\n",
    "    elif re.match('^1\\-[0-9]{3}\\-[0-9]{3}\\-[0-9]{4}$',test):\n",
    "        number = test.replace('-','')\n",
    "    elif re.match('^\\+1\\-[0-9]{3}\\-[0-9]{3}\\-[a-z]{4}$',test,flags=re.IGNORECASE):\n",
    "        number = '+1'+test[2:5]+test[6:9]+alpha_num(test[10:])\n",
    "    elif re.match('^\\([0-9]{3}\\)\\s[0-9]{3}\\-[a-z]{4}$',test,flags=re.IGNORECASE):\n",
    "        number = '+1'+test[1:4]+test[6:9]+alpha_num(test[10:])\n",
    "    else:\n",
    "        number = 'N/A'\n",
    "    test = number\n",
    "    return number\n",
    "\n",
    "#test = '1-650-938-NYNY'\n",
    "#print test\n",
    "#print format_phone(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1 408 736 6859\n",
      "+14087366859\n",
      "4087382177\n",
      "+14087382177\n",
      "+1 408 733 1304\n",
      "+14087331304\n",
      "408-498-4293\n",
      "+14084984293\n",
      "+1 408 739 7717\n",
      "+14087397717\n",
      "(408) 730-5510\n",
      "+14087305510\n",
      "+1 408 774 1889\n",
      "+14087741889\n",
      "+1-408-423-8502\n",
      "+14084238502\n",
      "4087369496\n",
      "+14087369496\n",
      "(408) 732-1573\n",
      "+14087321573\n",
      "4087386825\n",
      "+14087386825\n",
      "4087388761\n",
      "+14087388761\n",
      "4087361114\n",
      "+14087361114\n",
      "4088309933\n",
      "+14088309933\n",
      "4087388515\n",
      "+14087388515\n",
      "+1.408.245.5300\n",
      "+14082455300\n",
      "+1 408 830 9100\n",
      "+14088309100\n",
      "+1 408 220 6588\n",
      "+14082206588\n",
      "408 245 8988\n",
      "+14082458988\n",
      "+1 408 245 4423\n",
      "+14082454423\n",
      "+1 408 739 1282\n",
      "+14087391282\n",
      "+1 408 737 2852\n",
      "+14087372852\n",
      "+1 408 720 8111\n",
      "+14087208111\n",
      "+1-408-245-6463\n",
      "+14082456463\n",
      "+1-408-732-6218\n",
      "+14087326218\n",
      "+1 408 732 4280\n",
      "+14087324280\n",
      "+1 408 245 4100\n",
      "+14082454100\n",
      "650-969-3382\n",
      "+16509693382\n",
      "(408) 733-9446\n",
      "+14087339446\n",
      "+1 408 736 9888\n",
      "+14087369888\n",
      "+1 408 739 2251\n",
      "+14087392251\n",
      "(408) 530-9555\n",
      "+14085309555\n",
      "(408) 730-8784\n",
      "+14087308784\n",
      "(408) 735-9830\n",
      "+14087359830\n",
      "408.773.8095\n",
      "+14087738095\n",
      "(408) 738-CHEF\n",
      "+14087382433\n",
      "4082458828\n",
      "+14082458828\n",
      "4087208226\n",
      "+14087208226\n",
      "4082458392\n",
      "+14082458392\n",
      "+1 408 7339000\n",
      "+14087339000\n",
      "+1 408 736 7573\n",
      "+14087367573\n",
      "+1.408.735.5937\n",
      "+14087355937\n",
      "+1.408.720.1677\n",
      "+14087201677\n",
      "+1.408.245.5090\n",
      "+14082455090\n",
      "+1 408 732 3998\n",
      "+14087323998\n",
      "+1.408.498.9775\n",
      "+14084989775\n",
      "+1.855.244.7491\n",
      "+18552447491\n",
      "+1-408-481-9350\n",
      "+14084819350\n",
      "+1.408.469.4992\n",
      "+14084694992\n",
      "408-737-2020\n",
      "+14087372020\n",
      "4087390316\n",
      "+14087390316\n",
      "8002328669\n",
      "+18002328669\n",
      "4087208226\n",
      "+14087208226\n",
      "4087200322\n",
      "+14087200322\n",
      "4087469192\n",
      "+14087469192\n",
      "8008001914\n",
      "+18008001914\n",
      "4088309933\n",
      "+14088309933\n",
      "4087357448\n",
      "+14087357448\n",
      "4087337733\n",
      "+14087337733\n",
      "4088309594\n",
      "+14088309594\n",
      "4087321952\n",
      "+14087321952\n",
      "4087351102\n",
      "+14087351102\n",
      "4087309642\n",
      "+14087309642\n",
      "+1 408 746 9905\n",
      "+14087469905\n",
      "+1 408 746-0646\n",
      "+14087460646\n",
      "+1 408 733 3334\n",
      "+14087333334\n",
      "+1 408 738 0330\n",
      "+14087380330\n",
      "+1 408 245 1745\n",
      "+14082451745\n",
      "+1 408 998 5774\n",
      "+14089985774\n",
      "+1 408 720 0900\n",
      "+14087200900\n",
      "+1 408 774 9015\n",
      "+14087749015\n",
      "+1 408 530 0156\n",
      "+14085300156\n",
      "+1 408 498 7194\n",
      "+14084987194\n",
      "+1 888 255 3637\n",
      "+18882553637\n",
      "+1 408 735 1619\n",
      "+14087351619\n",
      "+1 408 685 2072\n",
      "+14086852072\n",
      "4082446009\n",
      "+14082446009\n",
      "+1 408 737 8587\n",
      "+14087378587\n",
      "+1 408 736 7588\n",
      "+14087367588\n",
      "+1 408 992 1020\n",
      "+14089921020\n",
      "+1 408 732 6200\n",
      "+14087326200\n",
      "4087367000\n",
      "+14087367000\n",
      "4087378812\n",
      "+14087378812\n",
      "1 408 732 4222\n",
      "+14087324222\n",
      "1 408 733 8473\n",
      "+14087338473\n",
      "4082491360\n",
      "+14082491360\n",
      "4087321475\n",
      "+14087321475\n",
      "4087377100\n",
      "+14087377100\n",
      "4085579975\n",
      "+14085579975\n",
      "4082476443\n",
      "+14082476443\n",
      "4082455720\n",
      "+14082455720\n",
      "4085429027\n",
      "+14085429027\n",
      "4087366008\n",
      "+14087366008\n",
      "4085308728\n",
      "+14085308728\n",
      "4087350335\n",
      "+14087350335\n",
      "4082441800\n",
      "+14082441800\n",
      "1 408 732 4222\n",
      "+14087324222\n",
      "4087208538\n",
      "+14087208538\n",
      "4088300094\n",
      "+14088300094\n",
      "4082436868\n",
      "+14082436868\n",
      "4087398960\n",
      "+14087398960\n",
      "4087067979\n",
      "+14087067979\n",
      "+1 408 245 2253\n",
      "+14082452253\n",
      "+1 408 245 9500\n",
      "+14082459500\n",
      "4084819432\n",
      "+14084819432\n",
      "4087365100\n",
      "+14087365100\n",
      "4082060164\n",
      "+14082060164\n",
      "+1 408 735 9300\n",
      "+14087359300\n",
      "+1 408 470 3704\n",
      "+14084703704\n",
      "+1 408 245 0014\n",
      "+14082450014\n",
      "+1 408 739 2084\n",
      "+14087392084\n",
      "4086168828\n",
      "+14086168828\n",
      "4082452020\n",
      "+14082452020\n",
      "+1 408 774 1424\n",
      "+14087741424\n",
      "+1 408 739 1798\n",
      "+14087391798\n",
      "+1-650-938-NYNY\n",
      "+1-65-93-6969\n",
      "408-739-2212\n",
      "+14087392212\n",
      "+1 408 245 8500\n",
      "+14082458500\n",
      "+1 408 739 9525\n",
      "+14087399525\n",
      "+1 408 737 0711\n",
      "+14087370711\n",
      "+1 408 245 6888\n",
      "+14082456888\n",
      "+1-408-716-4454\n",
      "+14087164454\n",
      "+1 408 733 1482\n",
      "+14087331482\n",
      "+1 408 940 6284\n",
      "+14089406284\n",
      "+1 408 245 2245\n",
      "+14082452245\n",
      "+1 408 733 5262\n",
      "+14087335262\n",
      "+1 408 984 5395\n",
      "+14089845395\n",
      "+1 408 244 7311\n",
      "+14082447311\n",
      "+1-408-746-9746\n",
      "+14087469746\n",
      "408-454-8459\n",
      "+14084548459\n",
      "+1 408 774 0595\n",
      "+14087740595\n",
      "+1 408 733 1111\n",
      "+14087331111\n",
      "+1 408 732 3350\n",
      "+14087323350\n",
      "+1 408 492 9304\n",
      "+14084929304\n",
      "+1 408 919 0088\n",
      "+14089190088\n",
      "+1.408.746.9583\n",
      "+14087469583\n",
      "+1.408.736.6688\n",
      "+14087366688\n",
      "+16502898186\n",
      "+16502898186\n",
      "(408) 510-0486\n",
      "+14085100486\n",
      "(408) 510-0486\n",
      "+14085100486\n",
      "(408) 564-7675\n",
      "+14085647675\n",
      "(408) 244-9922\n",
      "+14082449922\n",
      "+1 408 246 8800\n",
      "+14082468800\n",
      "+1 408 732 6200\n",
      "+14087326200\n",
      "408-773-1878\n",
      "+14087731878\n",
      "650-988-8886\n",
      "+16509888886\n",
      "650-625-0268\n",
      "+16506250268\n",
      "650-967-4171\n",
      "+16509674171\n",
      "408-736-2837\n",
      "+14087362837\n",
      "(408) 462-9176\n",
      "+14084629176\n",
      "+1 408 245 4350\n",
      "+14082454350\n",
      "+1 408 245 8585\n",
      "+14082458585\n",
      "408-734-5330\n",
      "+14087345330\n",
      "+1 408 246 1484\n",
      "+14082461484\n",
      "+1 408 220 2200\n",
      "+14082202200\n",
      "(669) 777-9035\n",
      "+16697779035\n",
      "+1-408-720-8689\n",
      "+14087208689\n",
      "(408) 732-8775\n",
      "+14087328775\n",
      "+1 408-962-0396\n",
      "+14089620396\n",
      "+1 408-730-9200\n",
      "+14087309200\n",
      "+1 408-260-2727\n",
      "+14082602727\n",
      "4085151007\n",
      "+14085151007\n",
      "+1-408-739-4560\n",
      "+14087394560\n",
      "+1 408-247-4300\n",
      "+14082474300\n",
      "650-969-3382\n",
      "+16509693382\n",
      "650-567-3737\n",
      "+16505673737\n",
      "4087208654\n",
      "+14087208654\n",
      "+1.408.245.3686\n",
      "+14082453686\n",
      "+1 408 617 1300\n",
      "+14086171300\n",
      "408-736-6255\n",
      "+14087366255\n",
      "+1.408.730.7100\n",
      "+14087307100\n",
      "+1.408.736.2630\n",
      "+14087362630\n",
      "+1-408-733-4200\n",
      "+14087334200\n",
      "650.988.6630\n",
      "+16509886630\n",
      "+1-408-292-4040\n",
      "+14082924040\n",
      "(408) 739-6588\n",
      "+14087396588\n",
      "+1-408-470-8000\n",
      "+14084708000\n",
      "+1-408-730-8117\n",
      "+14087308117\n",
      "+1-866-792-5905\n",
      "+18667925905\n",
      "4089919090\n",
      "+14089919090\n",
      "(408)-732-0300\n",
      "+14087320300\n",
      "+1 408 245 4571\n",
      "+14082454571\n",
      "+1 408 732 5002\n",
      "+14087325002\n",
      "408-733-2436\n",
      "+14087332436\n",
      "+1 408 707 2980\n",
      "+14087072980\n",
      "+1.408.730.7300\n",
      "+14087307300\n",
      "+1.408.720.9393\n",
      "+14087209393\n",
      "+1 408 2691048\n",
      "+14082691048\n",
      "+1 (408) 245-8434\n",
      "+14082458434\n",
      "+1 408 733 6611\n",
      "+14087336611\n",
      "+1 408 730 7758\n",
      "+14087307758\n",
      "(408) 830-0628\n",
      "+14088300628\n",
      "+1 408 245 7737\n",
      "+14082457737\n",
      "+1 408 732 2729\n",
      "+14087322729\n",
      "+1 408 245 3276\n",
      "+14082453276\n",
      "+1 408 733 2730\n",
      "+14087332730\n",
      "408-492-9055\n",
      "+14084929055\n",
      "1.408.736.4500\n",
      "+14087364500\n",
      "1.408.736.0921\n",
      "+14087360921\n",
      "1.408.738.1960\n",
      "+14087381960\n",
      "+1.408.738.1916\n",
      "+14087381916\n",
      "+1.408.771.0909\n",
      "+14087710909\n",
      "+1.408.245.4712\n",
      "+14082454712\n",
      "+1 408 736 5590\n",
      "+14087365590\n",
      "+1 408 736 3746\n",
      "+14087363746\n",
      "1.408.736.5411\n",
      "+14087365411\n",
      "1.408.245.5620\n",
      "+14082455620\n",
      "+1-800-673-9981\n",
      "+18006739981\n",
      "+1-408-737-8673\n",
      "+14087378673\n",
      "+1.408.245.5432\n",
      "+14082455432\n",
      "+1.408.732.2200\n",
      "+14087322200\n",
      "408-260-0404\n",
      "+14082600404\n",
      "650-969-3026\n",
      "+16509693026\n",
      "4087362895\n",
      "+14087362895\n",
      "+1 408 739 2022\n",
      "+14087392022\n",
      "+1 408 739 2022\n",
      "+14087392022\n",
      "+1 408 596 2583\n",
      "+14085962583\n",
      "+1 408 739 2383\n",
      "+14087392383\n",
      "+1 408 245 7338\n",
      "+14082457338\n",
      "+1 408 730 1468\n",
      "+14087301468\n",
      "+1 408 736 1315\n",
      "+14087361315\n",
      "+1 408 739 9248\n",
      "+14087399248\n",
      "+1 408 774 0700\n",
      "+14087740700\n",
      "+1 408 736 3726\n",
      "+14087363726\n",
      "408-720-8840\n",
      "+14087208840\n",
      "+1 408 739 3545\n",
      "+14087393545\n",
      "+1 408 738 4862\n",
      "+14087384862\n",
      "+1 408 739 7771\n",
      "+14087397771\n",
      "+1 408 739 9011\n",
      "+14087399011\n",
      "+1 408 969 9900\n",
      "+14089699900\n",
      "+1 408 735 7182\n",
      "+14087357182\n",
      "4087395533\n",
      "+14087395533\n",
      "+1 408 737 7376\n",
      "+14087377376\n",
      "+1 408 482 1367\n",
      "+14084821367\n",
      "+1 408 482 1367\n",
      "+14084821367\n",
      "+1 408 969 0887\n",
      "+14089690887\n",
      "+1 408 727 7907\n",
      "+14087277907\n",
      "866-684-3427\n",
      "+18666843427\n"
     ]
    }
   ],
   "source": [
    "for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "    if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "        for tag in elem.iter(\"tag\"):\n",
    "            if tag.attrib['k'] == 'phone':\n",
    "                #print 'woohoo'\n",
    "                print tag.attrib['v']\n",
    "                print format_phone(tag.attrib['v'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the above code I clearly see that it is lot clean already. There are only 2 places where the mapping I developed in the exercise was useful. Other street names which are listed above look genuine addresses only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows8_OS\n",
      " Volume Serial Number is 5298-EB2A\n",
      "\n",
      " Directory of C:\\Users\\Saisandeep\\Documents\\Udacity Data Analyst\\Data wrangling\n",
      "\n",
      "09/08/2017  01:44 PM    <DIR>          .\n",
      "09/08/2017  01:44 PM    <DIR>          ..\n",
      "08/22/2017  05:46 AM    <DIR>          .ipynb_checkpoints\n",
      "07/30/2017  04:09 PM         1,572,864 2013_ERCOT_Hourly_Load_Data.xls\n",
      "07/30/2017  11:46 AM           746,002 2013_ERCOT_Hourly_Load_Data.zip\n",
      "07/30/2017  04:09 PM               353 2013_Max_Loads.csv\n",
      "08/22/2017  06:48 AM    <DIR>          cerberus-master\n",
      "08/22/2017  06:47 AM           145,110 cerberus-master.zip\n",
      "09/08/2017  01:44 PM            54,933 Data Wrangling OSM Project.ipynb\n",
      "09/06/2017  05:46 AM           390,288 Data+Wrangling+OSM+Project.html\n",
      "08/12/2017  05:45 PM            37,054 Datawranglingrough.ipynb\n",
      "08/21/2017  07:29 AM        55,816,388 interpreter\n",
      "08/28/2017  07:12 PM        21,006,789 nodes.csv\n",
      "08/22/2017  08:01 AM           511,486 nodes_tags.csv\n",
      "09/08/2017  06:18 AM    <DIR>          py files\n",
      "09/08/2017  06:16 AM            18,952 Report.docx\n",
      "08/22/2017  07:33 AM             2,578 schema.py\n",
      "08/22/2017  07:37 AM             1,260 schema.pyc\n",
      "09/06/2017  05:49 AM         4,645,546 Submission.zip\n",
      "08/22/2017  08:01 AM         2,100,169 ways.csv\n",
      "08/22/2017  08:01 AM         7,327,854 ways_nodes.csv\n",
      "08/22/2017  08:01 AM         2,860,594 ways_tags.csv\n",
      "              17 File(s)     97,238,220 bytes\n",
      "               5 Dir(s)  18,890,735,616 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I have worked on the creating the csv files from the xml using the code worked on during exercise. I faced some challenges in making this code work due to multiple reasons. But I figured out how to fix it based on the error messages and print statements at every stage to understand error. \n",
    "\n",
    "Initially I could not get the packages Cerberus and Schema installed on my environment as conda was not able to search for them. Later I searched for a while to figure out the correct name it had to install with and some documentation on what these are used for. I enjoyed reading the materail and understand how the complete code is working. \n",
    "\n",
    "I also struggled using schema.py but the udacity forums helped me look for a solution for this issue. It is great learning for the furture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "import schema\n",
    "\n",
    "data = 'C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/interpreter'\n",
    "OSM_PATH = data\n",
    "\n",
    "NODES_PATH = \"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/nodes.csv\"\n",
    "NODE_TAGS_PATH = \"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/nodes_tags.csv\"\n",
    "WAYS_PATH = \"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/ways.csv\"\n",
    "WAY_NODES_PATH = \"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    #print element.tag\n",
    "    #print element.attrib\n",
    "    if element.tag == 'node':\n",
    "        for field in node_attr_fields:\n",
    "            #print field, element.attrib[field]\n",
    "            node_attribs[field] = element.attrib[field]\n",
    "    if element.tag == 'way':\n",
    "        for field in way_attr_fields:\n",
    "            #print field, element.attrib[field]\n",
    "            way_attribs[field] = element.attrib[field]\n",
    "        count = 0\n",
    "        for node in element.findall('nd'):\n",
    "            entry = {}\n",
    "            entry['id'] = element.attrib['id']\n",
    "            entry['node_id'] = node.attrib['ref']\n",
    "            entry['position'] = count\n",
    "            count = count +1\n",
    "            way_nodes.append(entry)\n",
    "        #print '-------------------------'\n",
    "        #print way_nodes\n",
    "                \n",
    "    for tag in element.findall('tag'):\n",
    "        entry = {}\n",
    "        \n",
    "        if is_street_name(tag):\n",
    "            entry['value'] = update_name(tag.attrib['v'], mapping)\n",
    "        elif tag.attrib['k'] == 'phone':\n",
    "            entry['value'] = format_phone(tag.attrib['v'])\n",
    "        else:\n",
    "            entry['value'] = tag.attrib['v']\n",
    "        \n",
    "        if ':' in tag.attrib['k']:\n",
    "            keys = tag.attrib['k'].split(':',1)\n",
    "            entry['type'] = keys[0]\n",
    "            entry['key'] = keys[1]\n",
    "        else:\n",
    "            entry['type'] = 'regular'\n",
    "            entry['key'] = tag.attrib['k']\n",
    "        entry['id'] = element.attrib['id']\n",
    "        tags.append(entry)\n",
    "        \n",
    "        \n",
    "    #print'-----------------------'\n",
    "    #print tags\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "process_map(OSM_PATH, validate = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I faced challenges loading file into database. Initially when I tried opening the csv files in excel it showed empty alternate rows. so I wrote the below function to confirm if there are empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35157, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "filename = 'C:/Users/Saisandeep/Documents/Udacity Data Analyst/Data wrangling/ways.csv'\n",
    "\n",
    "def emptyrowcounts(filename):\n",
    "    count = 0\n",
    "    rows = 0\n",
    "    with open(filename, 'r') as f:\n",
    "        for row in f:\n",
    "            if row:\n",
    "                rows = rows + 1\n",
    "            else:\n",
    "                count = count+1\n",
    "    return rows, count\n",
    "\n",
    "emptyrowcounts(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the above code on all the files and found there are no empty rows in the files and continued my struggle with the loading into database. After quite a bit of struggle and search online I realized its the issue with the datatype and decoding. Then I reached out the forums to check if someone else had similar issues and found a lot of help and guidence from previous discussions. I was able to figure out my mistakes and used python connection to sqlite database and performed below queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "database = 'C:/sqlite_windows/osm.db'\n",
    "\n",
    "con = sqlite3.connect(database)\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes; ''')\n",
    "con.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE nodes (id INTEGER PRIMARY KEY NOT NULL, lat REAL, lon REAL, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp DATE);\") # use your column names here\n",
    "con.commit()\n",
    "with open('C:/sqlite_windows/nodes.csv','rb') as fin: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['lat'].decode(\"utf-8\"),i['lon'].decode(\"utf-8\"),\\\n",
    "              i['user'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"),\\\n",
    "              i['changeset'].decode(\"utf-8\"), i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?,?,?);\", to_db)\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import pprint\n",
    "database = 'C:/sqlite_windows/osm.db'\n",
    "\n",
    "con = sqlite3.connect(database)\n",
    "cur = con.cursor()\n",
    "\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags; ''')\n",
    "con.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE nodes_tags (\\\n",
    "    id INTEGER,\\\n",
    "    key TEXT,\\\n",
    "    value TEXT,\\\n",
    "    type TEXT,\\\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id)\\\n",
    ");\") # use your column names here\n",
    "con.commit()\n",
    "\n",
    "with open('C:/sqlite_windows/nodes_tags.csv','rb') as fin: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),\\\n",
    "              i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "\n",
    "cur.executemany(\"INSERT INTO nodes_tags (id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = 'C:/sqlite_windows/osm.db'\n",
    "\n",
    "con = sqlite3.connect(database)\n",
    "cur = con.cursor()\n",
    "\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS ways; ''')\n",
    "con.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways (id INTEGER PRIMARY KEY NOT NULL, user TEXT,uid INTEGER,version TEXT,changeset INTEGER,timestamp TEXT);\") # use your column names here\n",
    "con.commit()\n",
    "\n",
    "with open('C:/sqlite_windows/ways.csv','rb') as fin: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['user'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"),\\\n",
    "              i['version'].decode(\"utf-8\"),i['changeset'].decode(\"utf-8\"),i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways (id, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?);\", to_db)\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = 'C:/sqlite_windows/osm.db'\n",
    "\n",
    "con = sqlite3.connect(database)\n",
    "cur = con.cursor()\n",
    "\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes; ''')\n",
    "con.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_nodes (id INTEGER NOT NULL,node_id INTEGER NOT NULL,position INTEGER NOT NULL,\\\n",
    "FOREIGN KEY (id) REFERENCES ways(id),FOREIGN KEY (node_id) REFERENCES nodes(id));\") # use your column names here\n",
    "con.commit()\n",
    "\n",
    "with open('C:/sqlite_windows/ways_nodes.csv','rb') as fin: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['node_id'].decode(\"utf-8\"),i['position'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_nodes (id, node_id, position) VALUES (?,?,?);\", to_db)\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = 'C:/sqlite_windows/osm.db'\n",
    "\n",
    "con = sqlite3.connect(database)\n",
    "cur = con.cursor()\n",
    "\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags; ''')\n",
    "con.commit()\n",
    "\n",
    "cur.execute(\"CREATE TABLE ways_tags (id INTEGER NOT NULL,key TEXT NOT NULL,value TEXT NOT NULL,\\\n",
    "type TEXT,FOREIGN KEY (id) REFERENCES ways(id));\") # use your column names here\n",
    "con.commit()\n",
    "\n",
    "with open('C:/sqlite_windows/ways_tags.csv','rb') as fin: # `with` statement available in 2.5+\n",
    "    # csv.DictReader uses first line in file for column headings by default\n",
    "    dr = csv.DictReader(fin) # comma is default delimiter\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),\\\n",
    "              i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "\n",
    "cur.executemany(\"INSERT INTO ways_tags (id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'andygol', 94578, 36924),\n",
      " (u'RichRico', 2219338, 31013),\n",
      " (u'karitotp', 2748195, 29270),\n",
      " (u'samely', 2512300, 24964),\n",
      " (u'n76', 318696, 21835),\n",
      " (u'dannykath', 2226712, 21037),\n",
      " (u'ediyes', 1240849, 17715),\n",
      " (u'calfarome', 2511706, 10594),\n",
      " (u'matthieun', 595221, 9457),\n",
      " (u'nikhilprabhakar', 2835928, 8185)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "import sqlite3\n",
    "\n",
    "def sqlquery(query):\n",
    "    database = 'C:/sqlite_windows/osm.db'\n",
    "    con = sqlite3.connect(database)\n",
    "    cur = con.cursor()\n",
    "    cur.execute(query)\n",
    "    pprint(cur.fetchall())\n",
    "    con.close()\n",
    "\n",
    "query = 'select user, uid, count(*) from nodes group by uid order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'andygol', 94578, 36924),\n",
      " (u'RichRico', 2219338, 31013),\n",
      " (u'karitotp', 2748195, 29270),\n",
      " (u'samely', 2512300, 24964),\n",
      " (u'n76', 318696, 21835),\n",
      " (u'dannykath', 2226712, 21037),\n",
      " (u'ediyes', 1240849, 17715),\n",
      " (u'calfarome', 2511706, 10594),\n",
      " (u'matthieun', 595221, 9457),\n",
      " (u'nikhilprabhakar', 2835928, 8185)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select user, uid, count(*) from nodes group by uid order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'housenumber', 2371),\n",
      " (u'street', 2320),\n",
      " (u'city', 1516),\n",
      " (u'highway', 1458),\n",
      " (u'name', 736),\n",
      " (u'amenity', 523),\n",
      " (u'source', 354),\n",
      " (u'postcode', 325),\n",
      " (u'addr', 257),\n",
      " (u'shop', 251)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select key, count(*) from nodes_tags group by key order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'restaurant', 127),\n",
      " (u'bicycle_parking', 68),\n",
      " (u'bench', 34),\n",
      " (u'fast_food', 31),\n",
      " (u'dentist', 23),\n",
      " (u'cafe', 22),\n",
      " (u'doctors', 20),\n",
      " (u'parking', 17),\n",
      " (u'atm', 15),\n",
      " (u'post_box', 15)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select value, count(*) from nodes_tags where key = \\'amenity\\' group by value order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'hairdresser', 25),\n",
      " (u'car_repair', 21),\n",
      " (u'beauty', 18),\n",
      " (u'supermarket', 15),\n",
      " (u'dry_cleaning', 11),\n",
      " (u'convenience', 10),\n",
      " (u'alcohol', 9),\n",
      " (u'laundry', 8),\n",
      " (u'clothes', 7),\n",
      " (u'jewelry', 6)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select value, count(*) from nodes_tags where key = \\'shop\\' group by value order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'stop', 504),\n",
      " (u'turning_circle', 346),\n",
      " (u'traffic_signals', 260),\n",
      " (u'crossing', 256),\n",
      " (u'bus_stop', 57),\n",
      " (u'give_way', 21),\n",
      " (u'motorway_junction', 10),\n",
      " (u'turning_loop', 3),\n",
      " (u'survey', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select value, count(*) from nodes_tags where key = \\'highway\\' group by value order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(250195022, 164),\n",
      " (38201877, 143),\n",
      " (39200808, 135),\n",
      " (49438764, 135),\n",
      " (228906414, 126),\n",
      " (49438925, 114),\n",
      " (390153611, 113),\n",
      " (390153610, 112),\n",
      " (47795407, 109),\n",
      " (474246349, 107)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select id, count(*) from ways_nodes group by id order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(49046539, 21),\n",
      " (26230997, 20),\n",
      " (22372547, 19),\n",
      " (26230999, 18),\n",
      " (30931570, 18),\n",
      " (340316602, 18),\n",
      " (41914255, 17),\n",
      " (49322007, 17),\n",
      " (311341167, 17),\n",
      " (311341170, 17)]\n"
     ]
    }
   ],
   "source": [
    "    query = 'select id, count(*) from ways_tags group by id order by count(*) desc limit 10;'\n",
    "    sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'building', 27627),\n",
      " (u'source', 6558),\n",
      " (u'highway', 5849),\n",
      " (u'street', 5341),\n",
      " (u'housenumber', 5338),\n",
      " (u'name', 3203),\n",
      " (u'maxspeed', 2614),\n",
      " (u'service', 2268),\n",
      " (u'lanes', 1964),\n",
      " (u'county', 1932)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select key, count(*) from ways_tags group by key order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'parking', 140),\n",
      " (u'restaurant', 26),\n",
      " (u'school', 26),\n",
      " (u'fuel', 23),\n",
      " (u'bank', 18),\n",
      " (u'fast_food', 17),\n",
      " (u'place_of_worship', 15),\n",
      " (u'swimming_pool', 10),\n",
      " (u'fountain', 7),\n",
      " (u'pharmacy', 5)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select value, count(*) from ways_tags where key = \\'amenity\\' group by value order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Perch338', u'restaurant', 127),\n",
      " (u'Harry Cutts', u'bicycle_parking', 68),\n",
      " (u'Minh Nguyen', u'bench', 34),\n",
      " (u'jgkamat', u'fast_food', 31),\n",
      " (u'jgkamat', u'dentist', 23),\n",
      " (u'WrErase', u'cafe', 22),\n",
      " (u'nmixter', u'doctors', 20),\n",
      " (u'Jonathan ZHAO', u'parking', 17),\n",
      " (u'matthieun', u'atm', 15),\n",
      " (u'fmarier', u'post_box', 15)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select a.user, b.value, count(*) from nodes a join nodes_tags b on a.id = b.id \\\n",
    "         where b.key = \\'amenity\\' group by b.value order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'housenumber', 2371),\n",
      " (u'street', 2320),\n",
      " (u'city', 1516),\n",
      " (u'highway', 1458),\n",
      " (u'name', 736),\n",
      " (u'amenity', 523),\n",
      " (u'source', 354),\n",
      " (u'postcode', 325),\n",
      " (u'addr', 257),\n",
      " (u'shop', 251),\n",
      " (u'crossing', 240),\n",
      " (u'direction', 240),\n",
      " (u'country', 193),\n",
      " (u'state', 181),\n",
      " (u'phone', 171),\n",
      " (u'cuisine', 154),\n",
      " (u'created_by', 133),\n",
      " (u'surface', 130),\n",
      " (u'website', 129),\n",
      " (u'date', 128)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select key, count(*) from nodes_tags group by key order by count(*) desc limit 20;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Perch338', u'indian', 25),\n",
      " (u'mvexel', u'chinese', 15),\n",
      " (u'jgkamat', u'sandwich', 15),\n",
      " (u'joeclmbr', u'pizza', 14),\n",
      " (u'n76', u'mexican', 9),\n",
      " (u'n76', u'thai', 8),\n",
      " (u'Minh Nguyen', u'korean', 7),\n",
      " (u'Minh Nguyen', u'burger', 5),\n",
      " (u'WrErase', u'coffee_shop', 5),\n",
      " (u'Minh Nguyen', u'japanese', 5)]\n"
     ]
    }
   ],
   "source": [
    "query = 'select a.user, b.value, count(*) from nodes a join nodes_tags b on a.id = b.id \\\n",
    "         where b.key = \\'cuisine\\' group by b.value order by count(*) desc limit 10;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'94087', 250),\n",
      " (u'94086', 231),\n",
      " (u'95051', 137),\n",
      " (u'94085', 25),\n",
      " (u'94040', 18),\n",
      " (u'94086-6406', 5),\n",
      " (u'95054', 5),\n",
      " (u'94041', 3),\n",
      " (u'94807', 2),\n",
      " (u'94087-2248', 1),\n",
      " (u'94087\\u200e', 1),\n",
      " (u'94088-3453', 1),\n",
      " (u'94088-3707', 1),\n",
      " (u'95050', 1),\n",
      " (u'95086', 1),\n",
      " (u'CA 94086', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) tags \\\n",
    "WHERE tags.key= \\'postcode\\' GROUP BY tags.value ORDER BY count DESC;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(250586,)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT COUNT(*) FROM nodes;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(35156,)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT COUNT(*) FROM ways;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(324,)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'andygol', 41907),\n",
      " (u'RichRico', 34222),\n",
      " (u'karitotp', 31478),\n",
      " (u'samely', 28559),\n",
      " (u'n76', 27198),\n",
      " (u'dannykath', 23103),\n",
      " (u'ediyes', 19664),\n",
      " (u'calfarome', 11449),\n",
      " (u'matthieun', 11309),\n",
      " (u'nikhilprabhakar', 9047)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT e.user, COUNT(*) as num \\\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e \\\n",
    "GROUP BY e.user \\\n",
    "ORDER BY num DESC \\\n",
    "LIMIT 10;' \n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(85,)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT COUNT(*) FROM (SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\\\n",
    " GROUP BY e.user HAVING num=1)  u;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'christian', 11), (u'unitarian_universalist', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value=\\'place_of_worship\\') i \\\n",
    "ON nodes_tags.id=i.id WHERE nodes_tags.key=\\'religion\\' GROUP BY nodes_tags.value ORDER BY num DESC;'\n",
    "sqlquery(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering my laptop configuration I choose to restrict myself with the size minimum requirement. \n",
    "\n",
    "File sizes:\n",
    "\n",
    "Sunnyvale.osm --------53.2 MB\n",
    "\n",
    "sunnyvale.db ---------28.5 MB\n",
    "\n",
    "nodes.csv ------------20.0 MB\n",
    "\n",
    "nodes_tags.csv--------500 KB\n",
    "\n",
    "ways.csv -------------2.0 MB\n",
    "\n",
    "ways_tags.csv---------2.73 MB\n",
    "\n",
    "ways_nodes.csv--------6.98 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the Sunnyvale area is incomplete, though I believe it has been well cleaned by the users before I started cleaning itself. I feel lot of information can be added to this data. I live in Sunnyvale and I observed few of the famous restaurants are missing and I was able to search for my home address and it was available in there. I tried to analyze what ever information I could imagine we can get from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test1]",
   "language": "python",
   "name": "conda-env-test1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
