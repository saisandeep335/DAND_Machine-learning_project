{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/final_project/tester.py\n",
    "#!/usr/bin/pickle\n",
    "\n",
    "\"\"\" a basic script for importing student's POI identifier,\n",
    "    and checking the results that they get from it \n",
    " \n",
    "    requires that the algorithm, dataset, and features list\n",
    "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
    "    my_feature_list.pkl, respectively\n",
    "\n",
    "    that process should happen at the end of poi_id.py\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  18\n",
      "Total no. of employees in dataset: 146\n",
      "Total no. of POI in dataset: 18\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd839d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/final_project/poi_id.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/tools/\")\n",
    "sys.path.append(\"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/final_project/\")\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances',\n",
    "                 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value',\n",
    "                 'expenses', 'exercised_stock_options', 'long_term_incentive',\n",
    "                 'restricted_stock', 'director_fees', 'to_messages', 'from_poi_to_this_person',\n",
    "                 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "# You will need to use more features\n",
    "\n",
    "print 'Number of features: ', len(features_list)-1\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/final_project\\\n",
    "/final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "#explore dataset\n",
    "\n",
    "#num = 0\n",
    "#for i in data_dict:\n",
    "#    num = num+1\n",
    "#    if num<3:\n",
    "#        print json.dumps(data_dict[i], indent=1)\n",
    "\n",
    "num_of_emp = len(data_dict)\n",
    "print 'Total no. of employees in dataset:', num_of_emp\n",
    "\n",
    "num_of_poi = 0\n",
    "for i in data_dict:\n",
    "    if data_dict[i]['poi']==True:\n",
    "        num_of_poi += 1\n",
    "\n",
    "print 'Total no. of POI in dataset:', num_of_poi\n",
    "\n",
    "\n",
    "features =['salary', 'bonus']\n",
    "data = featureFormat(data_dict, features)\n",
    "for point in data:\n",
    "    salary=point[0]\n",
    "    bonus=point[1]\n",
    "    plt.scatter(salary, bonus)\n",
    "plt.xlabel('salary')\n",
    "plt.ylabel('bonus')\n",
    "\n",
    "plt.show() # There is an outlier\n",
    "\n",
    "for i, v in data_dict.items():\n",
    "    if v['salary'] != 'NaN' and v['salary'] > 10000000:\n",
    "        print i\n",
    "\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0 )\n",
    "data_dict.pop('LOCKHART EUGENE E', 0)\n",
    "\n",
    "\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/tools/\")\n",
    "sys.path.append(\"C:/Users/Saisandeep/Documents/Udacity Data Analyst/Machine-Learning/ud120-projects/final_project/\")\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "all_features = ['poi', 'email_address', 'salary', 'to_messages', 'deferral_payments', 'total_payments', \\\n",
    "                'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', \\\n",
    "                'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', \\\n",
    "                'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', \\\n",
    "                'from_poi_to_this_person']\n",
    "\n",
    "fin_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', \\\n",
    "                'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', \\\n",
    "                'long_term_incentive', 'restricted_stock', 'director_fees']\n",
    "\n",
    "email_features = ['to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', \\\n",
    "                  'shared_receipt_with_poi']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "df = df.replace('NaN', np.nan)\n",
    "\n",
    "### Task 2: Remove outliers and deal with missing values\n",
    "\n",
    "df[financial_features] = df[financial_features].fillna(0)\n",
    "df[email_features] = df[email_features].fillna(df[email_features].median())\n",
    "\n",
    "# outliers\n",
    "df = df.drop('TOTAL')\n",
    "df = df[df.from_messages < 6000]\n",
    "df = df[df.to_messages < 10000]\n",
    "\n",
    "### Task 3: Create new feature(s)\n",
    "df['ratio_of_messages_to_poi'] = df.from_this_person_to_poi / df.from_messages\n",
    "df['ratio_of_messages_from_poi'] = df.from_poi_to_this_person / df.to_messages\n",
    "\n",
    "\n",
    "my_dataset = df.to_dict('index')\n",
    "\n",
    "features_list = [u'poi', u'salary', u'to_messages', u'deferral_payments', u'total_payments',\n",
    "       u'exercised_stock_options', u'bonus', u'restricted_stock',\n",
    "       u'shared_receipt_with_poi', u'expenses', u'from_messages', u'other',\n",
    "       u'long_term_incentive', u'fracion_of_messages_to_poi',\n",
    "       u'fracion_of_messages_from_poi']\n",
    "\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, make_scorer\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "\n",
    "# grid = {\n",
    "#     'base_estimator__criterion': ('gini', 'entropy'),\n",
    "#     'base_estimator__min_samples_leaf':range(1, 50, 5),\n",
    "#     'base_estimator__max_depth': range(1, 10),\n",
    "#     'n_estimators': range(1,10)\n",
    "# }\n",
    "\n",
    "# search = GridSearchCV(AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42), \n",
    "#                       grid, make_scorer(f1_score), cv=StratifiedKFold(labels), n_jobs=-1)\n",
    "\n",
    "# search.fit(features, labels)\n",
    "\n",
    "# print search.best_score_\n",
    "# print search.best_params_\n",
    "\n",
    "# clf = search.best_estimator_\n",
    "\n",
    "\n",
    "### To speed up the process of training the grid search is not included and the best parameters used.\n",
    "### This is as recommended by the reviewer\n",
    "best_params = {\n",
    "\t'n_estimators': 4, \n",
    "\t'base_estimator__criterion': 'gini', \n",
    "\t'base_estimator__max_depth': 3, \n",
    "\t'base_estimator__min_samples_leaf': 11}\n",
    "\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42)\n",
    "clf.set_params(**best_params)\n",
    "\n",
    "\n",
    "## Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "## check your results. You do not need to change anything below, but make sure\n",
    "## that the version of poi_id.py that you submit can be run on its own and\n",
    "## generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
